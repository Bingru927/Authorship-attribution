{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Loading finished\n"
     ]
    }
   ],
   "source": [
    "texts_train = []\n",
    "labels_train = []\n",
    "texts_test = []\n",
    "labels_test = []\n",
    "print(\"Loading data\")\n",
    "\n",
    "with open( 'darkreddit_authorship_attribution_anon/darkreddit_authorship_attribution_train_anon.jsonl','r') as f:\n",
    "    train_data = [json.loads(line) for line in f.readlines()]\n",
    "    f.close()\n",
    "with open(\n",
    "        'darkreddit_authorship_attribution_anon/darkreddit_authorship_attribution_train_anon.jsonl','r') as f:\n",
    "    for line in f:\n",
    "        line = json.loads(line)\n",
    "        for key, value in line.items():\n",
    "            if key == 'author':\n",
    "                labels_train.append(value)\n",
    "            elif key == 'comment':\n",
    "                texts_train.append(value)\n",
    "    f.close()\n",
    "    a1 = [line['comment'] for line in train_data if line[\"author\"] == \"user1\"]\n",
    "    a2 = [line['comment'] for line in train_data if line[\"author\"] == \"user2\"]\n",
    "    a3 = [line['comment'] for line in train_data if line[\"author\"] == \"user3\"]\n",
    "    a4 = [line['comment'] for line in train_data if line[\"author\"] == \"user4\"]\n",
    "    a5 = [line['comment'] for line in train_data if line[\"author\"] == \"user5\"]\n",
    "    a6 = [line['comment'] for line in train_data if line[\"author\"] == \"user6\"]\n",
    "    a7 = [line['comment'] for line in train_data if line[\"author\"] == \"user7\"]\n",
    "    a8 = [line['comment'] for line in train_data if line[\"author\"] == \"user8\"]\n",
    "    a9 = [line['comment'] for line in train_data if line[\"author\"] == \"user9\"]\n",
    "    a10 = [line['comment'] for line in train_data if line[\"author\"] == \"user10\"]\n",
    "with open(\n",
    "        '/Users/bingru/Workspace/ML/IndividualProject/Data/darkreddit_authorship_attribution_anon/darkreddit_authorship_attribution_test_anon.jsonl',\n",
    "        'r') as f:\n",
    "    for line in f:\n",
    "        line = json.loads(line)\n",
    "        for key, value in line.items():\n",
    "            if key == 'author':\n",
    "                labels_test.append(value)\n",
    "            elif key == 'comment':\n",
    "                texts_test.append(value)\n",
    "    f.close()\n",
    "print(\"Loading finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train data : 100%|██████████| 6817/6817 [00:00<00:00, 23715.60it/s]\n",
      "Processing test data : 100%|██████████| 2276/2276 [00:00<00:00, 23669.90it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_pre = []\n",
    "X_test_pre = []\n",
    "Y_train = labels_train\n",
    "Y_test = labels_test\n",
    "\n",
    "# 数据预处理\n",
    "for text in tqdm.tqdm(texts_train, desc=\"Processing train data \"):\n",
    "    text = re.sub(r'http\\S+', 'URL', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[@$%^&*()]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    X_train_pre.append(text)\n",
    "\n",
    "for text in tqdm.tqdm(texts_test, desc=\"Processing test data \"):\n",
    "    text = re.sub(r'http\\S+', 'URL', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[@$%^&*()]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    X_test_pre.append(text)\n",
    "\n",
    "\n",
    "Y_train = labels_train\n",
    "Y_test = labels_test\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be curious what drugs are actually cheaper on the darknet than buying directly from the pharmacy even w/o insurance.  Painkillers are def. not cheaper on the darknet.  Maybe some others are cheaper, like bought from Canada or some shit.  I call bullshit on some of hte stats.  They said half the drugs bought are counterfeit?  I think it depends on where you buy them.  If you buy from an Indian pharmacy, sure they will be counterfeit, or from vendors who buy from these offshore pharmas.  But that's unfair to lump that b/c if you order from them, you've gotta realize you are not getting American pharmaceutical grade drugs.  There was a very expensive cancer drug that was counterfeited and sold to LEGITIMATE pharmas and hospitals - this is problematic not just on the DNMs.  In my mind, they need to use a stat of \"counterfeits\" that truly imitate a known medication - like the same pill shape, color, stamps, etc.  \n",
      "\n",
      "I've been thinking of doing spot checking on my orders (which aren't very many) and sending to those labs that will test the pill.  If this would interest anyone else, I could post the results here.  But not sure how helpful it'd be to the community since my drug range is very narrow and only order from a few vendors at the present.  I'm definitely going to do it for my own ease b/c I'm paranoid by nature and would like some assurance.  I have no reason to suspect otherwise, but its always nice to have confirmation.  \n",
      "\n",
      "I'd even contribute to others sending out a pill to a lab and posting the results.  I think that's highly beneficial to the community, esp amongst the pill people.\n"
     ]
    }
   ],
   "source": [
    "print(texts_train[3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def preprocess(texts_train):\n",
    "    X_text = []\n",
    "    for text in tqdm.tqdm(texts_train, desc=\"Processing train data \"):\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text = re.sub(r'[@$%^&*()]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        X_text.append(text)\n",
    "    return X_text\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Remove emoji characters from text (only Chinese English and numbers are retained)\n",
    "def clear_character(sentence):\n",
    "    line = re.sub(r'[@$%^&*()]', '', sentence)\n",
    "    line = re.sub(r'http\\S+', '', line)\n",
    "    # line = re.sub(r'[^\\w\\s]', '', line)\n",
    "    new_sentence = ' '.join(line.split())\n",
    "    return new_sentence\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "author = [clear_character(data) for data in X_train_pre]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[['lol',\n  'I',\n  'dont',\n  'think',\n  'youd',\n  'be',\n  'fucking',\n  'over',\n  'DeafPirateRoberts',\n  'by',\n  'doing',\n  'that',\n  'He',\n  'was',\n  'giving',\n  'you',\n  'a',\n  'valid',\n  'warning',\n  'Use',\n  'of',\n  'a',\n  'drop',\n  'is',\n  'a',\n  'lot',\n  'more',\n  'difficult',\n  'to',\n  'pull',\n  'off',\n  'Past',\n  'success',\n  'is',\n  'not',\n  'a',\n  'good',\n  'predictor',\n  'of',\n  'future',\n  'success',\n  'in',\n  'this',\n  'game',\n  'as',\n  'all',\n  'it',\n  'takes',\n  'is',\n  'one',\n  'returned',\n  'to',\n  'sender',\n  'one',\n  'suspicious',\n  'postman',\n  'etc',\n  'etc',\n  'Assume',\n  'your',\n  'drop',\n  'is',\n  'a',\n  'vacant',\n  'home',\n  'If',\n  'so',\n  'risky',\n  'Get',\n  'a',\n  'POBox',\n  'they',\n  'are',\n  'cheap']]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "train_seg_text_1 =[word_tokenize(s) for s in author]\n",
    "train_seg_text_1[:1]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster=LancasterStemmer()\n",
    "# 去掉文本中的停用词\n",
    "def drop_stopwords(line):\n",
    "    line_clean = []\n",
    "    for word in line:\n",
    "        word = lancaster.stem(word)\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        if word in ['thi','wa','lol','fuck','gt','le','mr','ar','etc','hav','dont','us','yo','mor','ov','youd','lik','ther','al','dos']:\n",
    "            continue\n",
    "        line_clean.append(word)\n",
    "    return line_clean\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "outputs": [
    {
     "data": {
      "text/plain": "[['think',\n  'deafpiraterobert',\n  'giv',\n  'valid',\n  'warn',\n  'drop',\n  'lot',\n  'difficult',\n  'pul',\n  'past',\n  'success',\n  'good',\n  'predict',\n  'fut',\n  'success',\n  'gam',\n  'tak',\n  'return',\n  'send',\n  'suspicy',\n  'postm',\n  'assum',\n  'drop',\n  'vac',\n  'hom',\n  'risky',\n  'get',\n  'pobox',\n  'cheap']]"
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_st_text = [drop_stopwords(s) for s in train_seg_text_1]\n",
    "train_st_text[:1]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(train_st_text, min_count=10, threshold=200) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[train_st_text], threshold=200)\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['think', 'deafpiraterobert', 'giv', 'valid', 'warn', 'drop', 'lot', 'difficult', 'pul', 'past', 'success', 'good', 'predict', 'fut', 'success', 'gam', 'tak', 'return', 'send', 'suspicy', 'postm', 'assum', 'drop', 'vac', 'hom', 'risky', 'get', 'pobox', 'cheap']]\n"
     ]
    }
   ],
   "source": [
    "data_words_bigrams = make_bigrams(train_st_text)\n",
    "print(data_words_bigrams[:1])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)]]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "id2word = corpora.Dictionary(data_words_bigrams)     # Create Dictionary\n",
    "id2word.save_as_text(\"dictionary\")                   # save dict\n",
    "texts = data_words_bigrams                           # Create Corpus\n",
    "corpus = [id2word.doc2bow(text) for text in texts]   # Term Document Frequency\n",
    "print(corpus[:1])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "outputs": [
    {
     "data": {
      "text/plain": "'alway'"
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[100]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('assum', 1), ('cheap', 1), ('deafpiraterobert', 1), ('difficult', 1), ('drop', 2), ('fut', 1), ('gam', 1), ('get', 1), ('giv', 1), ('good', 1), ('hom', 1), ('lot', 1), ('past', 1), ('pobox', 1), ('postm', 1), ('predict', 1), ('pul', 1), ('return', 1), ('risky', 1), ('send', 1), ('success', 2), ('suspicy', 1), ('tak', 1), ('think', 1), ('vac', 1), ('valid', 1), ('warn', 1)]]\n"
     ]
    }
   ],
   "source": [
    "print([[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10,\n",
    "                                           random_state=100,\n",
    "                                           update_every=10,\n",
    "                                           chunksize=100,\n",
    "                                           passes=30,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.072*\"key\" + 0.049*\"pgp\" + 0.040*\"encrypt\" + 0.025*\"mess\" + 0.015*\"publ\" + 0.012*\"password\" + 0.010*\"sign\" + 0.010*\"ver\" + 0.010*\"pac\" + 0.010*\"email\"'), (1, '0.018*\"salt\" + 0.016*\"dpr\" + 0.015*\"adderal\" + 0.010*\"astrid\" + 0.010*\"bud\" + 0.009*\"payp\" + 0.009*\"colorado\" + 0.008*\"rent\" + 0.008*\"rdarknetmarketsnoob\" + 0.006*\"top_shelf\"'), (2, '0.044*\"meth\" + 0.018*\"smok\" + 0.013*\"chem\" + 0.008*\"pur\" + 0.008*\"high\" + 0.008*\"acid\" + 0.008*\"cut\" + 0.007*\"powd\" + 0.007*\"wee\" + 0.007*\"bud\"'), (3, '0.030*\"pil\" + 0.017*\"pric\" + 0.016*\"med\" + 0.014*\"norco\" + 0.011*\"prescrib\" + 0.011*\"doct\" + 0.011*\"mg\" + 0.010*\"heroin\" + 0.010*\"oxy\" + 0.010*\"high\"'), (4, '0.011*\"would\" + 0.008*\"peopl\" + 0.008*\"wer\" + 0.007*\"market\" + 0.007*\"could\" + 0.007*\"serv\" + 0.007*\"drug\" + 0.006*\"think\" + 0.006*\"sit\" + 0.006*\"act\"'), (5, '0.051*\"post\" + 0.032*\"rul\" + 0.029*\"quest\" + 0.024*\"thread\" + 0.018*\"remov\" + 0.017*\"sourc\" + 0.017*\"mod\" + 0.016*\"subreddit\" + 0.015*\"threads\" + 0.014*\"pleas\"'), (6, '0.011*\"lab\" + 0.010*\"alprazolam\" + 0.009*\"pil\" + 0.009*\"pic\" + 0.009*\"cocain\" + 0.008*\"tablet\" + 0.008*\"eth\" + 0.007*\"schedule_ii\" + 0.007*\"val\" + 0.007*\"ind\"'), (7, '0.052*\"pack\" + 0.034*\"mail\" + 0.031*\"grand_wizard\" + 0.018*\"address\" + 0.014*\"get\" + 0.013*\"track\" + 0.012*\"ord\" + 0.012*\"sign\" + 0.011*\"op\" + 0.010*\"post\"'), (8, '0.059*\"bitcoin\" + 0.032*\"wallet\" + 0.029*\"escrow\" + 0.021*\"coin\" + 0.021*\"transact\" + 0.019*\"buy\" + 0.017*\"tumbl\" + 0.017*\"btc\" + 0.016*\"multisig\" + 0.015*\"money\"'), (9, '0.020*\"vend\" + 0.015*\"get\" + 0.010*\"tim\" + 0.010*\"wil\" + 0.008*\"peopl\" + 0.008*\"know\" + 0.008*\"im\" + 0.008*\"real\" + 0.008*\"would\" + 0.008*\"ev\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "print(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.072*\"key\" + 0.049*\"pgp\" + 0.040*\"encrypt\" + 0.025*\"mess\" + 0.015*\"publ\" + 0.012*\"password\" + 0.010*\"sign\" + 0.010*\"ver\" + 0.010*\"pac\" + 0.010*\"email\"'), (1, '0.018*\"salt\" + 0.016*\"dpr\" + 0.015*\"adderal\" + 0.010*\"astrid\" + 0.010*\"bud\" + 0.009*\"payp\" + 0.009*\"colorado\" + 0.008*\"rent\" + 0.008*\"rdarknetmarketsnoob\" + 0.006*\"top_shelf\"'), (2, '0.044*\"meth\" + 0.018*\"smok\" + 0.013*\"chem\" + 0.008*\"pur\" + 0.008*\"high\" + 0.008*\"acid\" + 0.008*\"cut\" + 0.007*\"powd\" + 0.007*\"wee\" + 0.007*\"bud\"'), (3, '0.030*\"pil\" + 0.017*\"pric\" + 0.016*\"med\" + 0.014*\"norco\" + 0.011*\"prescrib\" + 0.011*\"doct\" + 0.011*\"mg\" + 0.010*\"heroin\" + 0.010*\"oxy\" + 0.010*\"high\"'), (4, '0.011*\"would\" + 0.008*\"peopl\" + 0.008*\"wer\" + 0.007*\"market\" + 0.007*\"could\" + 0.007*\"serv\" + 0.007*\"drug\" + 0.006*\"think\" + 0.006*\"sit\" + 0.006*\"act\"'), (5, '0.051*\"post\" + 0.032*\"rul\" + 0.029*\"quest\" + 0.024*\"thread\" + 0.018*\"remov\" + 0.017*\"sourc\" + 0.017*\"mod\" + 0.016*\"subreddit\" + 0.015*\"threads\" + 0.014*\"pleas\"'), (6, '0.011*\"lab\" + 0.010*\"alprazolam\" + 0.009*\"pil\" + 0.009*\"pic\" + 0.009*\"cocain\" + 0.008*\"tablet\" + 0.008*\"eth\" + 0.007*\"schedule_ii\" + 0.007*\"val\" + 0.007*\"ind\"'), (7, '0.052*\"pack\" + 0.034*\"mail\" + 0.031*\"grand_wizard\" + 0.018*\"address\" + 0.014*\"get\" + 0.013*\"track\" + 0.012*\"ord\" + 0.012*\"sign\" + 0.011*\"op\" + 0.010*\"post\"'), (8, '0.059*\"bitcoin\" + 0.032*\"wallet\" + 0.029*\"escrow\" + 0.021*\"coin\" + 0.021*\"transact\" + 0.019*\"buy\" + 0.017*\"tumbl\" + 0.017*\"btc\" + 0.016*\"multisig\" + 0.015*\"money\"'), (9, '0.020*\"vend\" + 0.015*\"get\" + 0.010*\"tim\" + 0.010*\"wil\" + 0.008*\"peopl\" + 0.008*\"know\" + 0.008*\"im\" + 0.008*\"real\" + 0.008*\"would\" + 0.008*\"ev\"')]\n"
     ]
    }
   ],
   "source": [
    "print(lda_model.print_topics(num_topics=10, num_words=10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.68283802485318\n",
      "\n",
      "Coherence Score:  0.5362299152320135\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words_bigrams, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)   # 越高越好\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, [('key', 0.07169191), ('pgp', 0.049270667), ('encrypt', 0.0401884), ('mess', 0.024734303), ('publ', 0.014669663), ('password', 0.012023518), ('sign', 0.009954552), ('ver', 0.009922667), ('pac', 0.009592665), ('email', 0.009571234)]), (1, [('salt', 0.017500805), ('dpr', 0.016287224), ('adderal', 0.014531845), ('astrid', 0.01037461), ('bud', 0.009704079), ('payp', 0.0093366355), ('colorado', 0.008836624), ('rent', 0.008189249), ('rdarknetmarketsnoob', 0.008018155), ('top_shelf', 0.005818526)]), (2, [('meth', 0.044147454), ('smok', 0.018335162), ('chem', 0.013389048), ('pur', 0.008281842), ('high', 0.008238889), ('acid', 0.008040826), ('cut', 0.007995935), ('powd', 0.0069457693), ('wee', 0.0069129355), ('bud', 0.0068285298)]), (3, [('pil', 0.030330708), ('pric', 0.016728248), ('med', 0.015647344), ('norco', 0.013743944), ('prescrib', 0.011295329), ('doct', 0.010901636), ('mg', 0.010887765), ('heroin', 0.010365998), ('oxy', 0.009938042), ('high', 0.009755102)]), (4, [('would', 0.010551266), ('peopl', 0.007900229), ('wer', 0.0077071814), ('market', 0.007398857), ('could', 0.006756364), ('serv', 0.006694406), ('drug', 0.0065882965), ('think', 0.006002349), ('sit', 0.0058036665), ('act', 0.005591091)]), (5, [('post', 0.05147334), ('rul', 0.03202807), ('quest', 0.028935468), ('thread', 0.02401639), ('remov', 0.017864393), ('sourc', 0.017345546), ('mod', 0.016847843), ('subreddit', 0.015869798), ('threads', 0.015018222), ('pleas', 0.013858763)]), (6, [('lab', 0.011406951), ('alprazolam', 0.010439307), ('pil', 0.009311374), ('pic', 0.008586848), ('cocain', 0.00855722), ('tablet', 0.008121785), ('eth', 0.007661376), ('schedule_ii', 0.007463915), ('val', 0.0068659135), ('ind', 0.006717272)]), (7, [('pack', 0.052141156), ('mail', 0.03367324), ('grand_wizard', 0.03136806), ('address', 0.017869817), ('get', 0.014243416), ('track', 0.013364049), ('ord', 0.012212417), ('sign', 0.011924305), ('op', 0.010544474), ('post', 0.010150535)]), (8, [('bitcoin', 0.058750108), ('wallet', 0.031603307), ('escrow', 0.028815683), ('coin', 0.021081572), ('transact', 0.02074373), ('buy', 0.018771108), ('tumbl', 0.016888654), ('btc', 0.016759746), ('multisig', 0.016178835), ('money', 0.014805998)]), (9, [('vend', 0.019786105), ('get', 0.014914782), ('tim', 0.009675131), ('wil', 0.009553506), ('peopl', 0.008419425), ('know', 0.008354438), ('im', 0.0083123185), ('real', 0.008146822), ('would', 0.008109792), ('ev', 0.008002583)])]\n",
      "\n",
      "Coherence Score:  0.5362299152320135\n"
     ]
    }
   ],
   "source": [
    "# Show Topics\n",
    "print(lda_model.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=lda_model, texts=data_words_bigrams, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = lda_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0,\n  [('key', 0.07169191),\n   ('pgp', 0.049270667),\n   ('encrypt', 0.0401884),\n   ('mess', 0.024734303),\n   ('publ', 0.014669663),\n   ('password', 0.012023518),\n   ('sign', 0.009954552),\n   ('ver', 0.009922667),\n   ('pac', 0.009592665),\n   ('email', 0.009571234)]),\n (1,\n  [('salt', 0.017500805),\n   ('dpr', 0.016287224),\n   ('adderal', 0.014531845),\n   ('astrid', 0.01037461),\n   ('bud', 0.009704079),\n   ('payp', 0.0093366355),\n   ('colorado', 0.008836624),\n   ('rent', 0.008189249),\n   ('rdarknetmarketsnoob', 0.008018155),\n   ('top_shelf', 0.005818526)]),\n (2,\n  [('meth', 0.044147454),\n   ('smok', 0.018335162),\n   ('chem', 0.013389048),\n   ('pur', 0.008281842),\n   ('high', 0.008238889),\n   ('acid', 0.008040826),\n   ('cut', 0.007995935),\n   ('powd', 0.0069457693),\n   ('wee', 0.0069129355),\n   ('bud', 0.0068285298)]),\n (3,\n  [('pil', 0.030330708),\n   ('pric', 0.016728248),\n   ('med', 0.015647344),\n   ('norco', 0.013743944),\n   ('prescrib', 0.011295329),\n   ('doct', 0.010901636),\n   ('mg', 0.010887765),\n   ('heroin', 0.010365998),\n   ('oxy', 0.009938042),\n   ('high', 0.009755102)]),\n (4,\n  [('would', 0.010551266),\n   ('peopl', 0.007900229),\n   ('wer', 0.0077071814),\n   ('market', 0.007398857),\n   ('could', 0.006756364),\n   ('serv', 0.006694406),\n   ('drug', 0.0065882965),\n   ('think', 0.006002349),\n   ('sit', 0.0058036665),\n   ('act', 0.005591091)]),\n (5,\n  [('post', 0.05147334),\n   ('rul', 0.03202807),\n   ('quest', 0.028935468),\n   ('thread', 0.02401639),\n   ('remov', 0.017864393),\n   ('sourc', 0.017345546),\n   ('mod', 0.016847843),\n   ('subreddit', 0.015869798),\n   ('threads', 0.015018222),\n   ('pleas', 0.013858763)]),\n (6,\n  [('lab', 0.011406951),\n   ('alprazolam', 0.010439307),\n   ('pil', 0.009311374),\n   ('pic', 0.008586848),\n   ('cocain', 0.00855722),\n   ('tablet', 0.008121785),\n   ('eth', 0.007661376),\n   ('schedule_ii', 0.007463915),\n   ('val', 0.0068659135),\n   ('ind', 0.006717272)]),\n (7,\n  [('pack', 0.052141156),\n   ('mail', 0.03367324),\n   ('grand_wizard', 0.03136806),\n   ('address', 0.017869817),\n   ('get', 0.014243416),\n   ('track', 0.013364049),\n   ('ord', 0.012212417),\n   ('sign', 0.011924305),\n   ('op', 0.010544474),\n   ('post', 0.010150535)]),\n (8,\n  [('bitcoin', 0.058750108),\n   ('wallet', 0.031603307),\n   ('escrow', 0.028815683),\n   ('coin', 0.021081572),\n   ('transact', 0.02074373),\n   ('buy', 0.018771108),\n   ('tumbl', 0.016888654),\n   ('btc', 0.016759746),\n   ('multisig', 0.016178835),\n   ('money', 0.014805998)]),\n (9,\n  [('vend', 0.019786105),\n   ('get', 0.014914782),\n   ('tim', 0.009675131),\n   ('wil', 0.009553506),\n   ('peopl', 0.008419425),\n   ('know', 0.008354438),\n   ('im', 0.0083123185),\n   ('real', 0.008146822),\n   ('would', 0.008109792),\n   ('ev', 0.008002583)])]"
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "model_topics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.072*\"key\" + 0.049*\"pgp\" + 0.040*\"encrypt\" + 0.025*\"mess\" + 0.015*\"publ\" + 0.012*\"password\" + 0.010*\"sign\" + 0.010*\"ver\" + 0.010*\"pac\" + 0.010*\"email\"'), (1, '0.018*\"salt\" + 0.016*\"dpr\" + 0.015*\"adderal\" + 0.010*\"astrid\" + 0.010*\"bud\" + 0.009*\"payp\" + 0.009*\"colorado\" + 0.008*\"rent\" + 0.008*\"rdarknetmarketsnoob\" + 0.006*\"top_shelf\"'), (2, '0.044*\"meth\" + 0.018*\"smok\" + 0.013*\"chem\" + 0.008*\"pur\" + 0.008*\"high\" + 0.008*\"acid\" + 0.008*\"cut\" + 0.007*\"powd\" + 0.007*\"wee\" + 0.007*\"bud\"'), (3, '0.030*\"pil\" + 0.017*\"pric\" + 0.016*\"med\" + 0.014*\"norco\" + 0.011*\"prescrib\" + 0.011*\"doct\" + 0.011*\"mg\" + 0.010*\"heroin\" + 0.010*\"oxy\" + 0.010*\"high\"'), (4, '0.011*\"would\" + 0.008*\"peopl\" + 0.008*\"wer\" + 0.007*\"market\" + 0.007*\"could\" + 0.007*\"serv\" + 0.007*\"drug\" + 0.006*\"think\" + 0.006*\"sit\" + 0.006*\"act\"'), (5, '0.051*\"post\" + 0.032*\"rul\" + 0.029*\"quest\" + 0.024*\"thread\" + 0.018*\"remov\" + 0.017*\"sourc\" + 0.017*\"mod\" + 0.016*\"subreddit\" + 0.015*\"threads\" + 0.014*\"pleas\"'), (6, '0.011*\"lab\" + 0.010*\"alprazolam\" + 0.009*\"pil\" + 0.009*\"pic\" + 0.009*\"cocain\" + 0.008*\"tablet\" + 0.008*\"eth\" + 0.007*\"schedule_ii\" + 0.007*\"val\" + 0.007*\"ind\"'), (7, '0.052*\"pack\" + 0.034*\"mail\" + 0.031*\"grand_wizard\" + 0.018*\"address\" + 0.014*\"get\" + 0.013*\"track\" + 0.012*\"ord\" + 0.012*\"sign\" + 0.011*\"op\" + 0.010*\"post\"'), (8, '0.059*\"bitcoin\" + 0.032*\"wallet\" + 0.029*\"escrow\" + 0.021*\"coin\" + 0.021*\"transact\" + 0.019*\"buy\" + 0.017*\"tumbl\" + 0.017*\"btc\" + 0.016*\"multisig\" + 0.015*\"money\"'), (9, '0.020*\"vend\" + 0.015*\"get\" + 0.010*\"tim\" + 0.010*\"wil\" + 0.008*\"peopl\" + 0.008*\"know\" + 0.008*\"im\" + 0.008*\"real\" + 0.008*\"would\" + 0.008*\"ev\"')]\n"
     ]
    }
   ],
   "source": [
    "print(optimal_model.print_topics(num_words=10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
